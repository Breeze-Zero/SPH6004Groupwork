{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85962d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_cols = [\n",
    "    \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\",\n",
    "    \"Lung Lesion\", \"Edema\", \"Consolidation\", \"Pneumonia\",\n",
    "    \"Atelectasis\", \"Pneumothorax\", \"Pleural Effusion\",\n",
    "    \"Pleural Other\", \"Fracture\", \"Support Devices\"\n",
    "]\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"text\"] = df[\"text\"].fillna(\"NA\")\n",
    "    df[label_cols] = df[label_cols].fillna(0).astype(float)\n",
    "    df[\"labels\"] = df[label_cols].values.tolist()\n",
    "    return df.drop(columns=label_cols).reset_index(drop=True)\n",
    "\n",
    "def load_and_clean_all(train_path: str, dev_path: str, test_path: str) -> DatasetDict:\n",
    "    dfs = [clean_dataframe(pd.read_csv(p)) for p in (train_path, dev_path, test_path)]\n",
    "    sets = [Dataset.from_pandas(df, preserve_index=False) for df in dfs]\n",
    "    return DatasetDict({\"train\": sets[0], \"validation\": sets[1], \"test\": sets[2]})\n",
    "\n",
    "train_file = \"/text_test_data_noimpression.csv\"\n",
    "dev_file   = \"/text_val_data_noimpression.csv\"\n",
    "test_file  = \"/text_test_data_noimpression.csv\"\n",
    "raw_datasets = load_and_clean_all(train_file, dev_file, test_file)\n",
    "\n",
    "class CLSEmbeddingZeroShot:\n",
    "    def __init__(self, model_names, candidate_labels, device=-1):\n",
    "        self.device = torch.device(f\"cuda:{device}\" if device>=0 and torch.cuda.is_available() else \"cpu\")\n",
    "        self.models = {}\n",
    "        self.tokenizers = {}\n",
    "        self.label_embs = {}\n",
    "        self.candidate_labels = candidate_labels\n",
    "        for name in model_names:\n",
    "            tok = AutoTokenizer.from_pretrained(name)\n",
    "            model = BertModel.from_pretrained(name).to(self.device)\n",
    "            model.eval()\n",
    "            inputs = tok(candidate_labels, padding=True, return_tensors=\"pt\").to(self.device)\n",
    "            with torch.no_grad():\n",
    "                out = model(**inputs)\n",
    "                vec = out.pooler_output if hasattr(out, 'pooler_output') else out.last_hidden_state[:,0,:]\n",
    "                normed = F.normalize(vec, p=2, dim=1)\n",
    "            self.tokenizers[name] = tok\n",
    "            self.models[name] = model\n",
    "            self.label_embs[name] = normed.cpu()\n",
    "\n",
    "    def classify_batch(self, texts):\n",
    "        results = {}\n",
    "        for name, model in self.models.items():\n",
    "            tok = self.tokenizers[name]\n",
    "            all_vecs = []\n",
    "            for text in texts:\n",
    "                inputs = tok(text, padding=True, return_tensors=\"pt\").to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(**inputs)\n",
    "                    vec = out.pooler_output if hasattr(out, 'pooler_output') else out.last_hidden_state[:,0,:]\n",
    "                    normed = F.normalize(vec, p=2, dim=1).cpu()\n",
    "                all_vecs.append(normed)\n",
    "            text_emb = torch.vstack(all_vecs)\n",
    "            sims = text_emb @ self.label_embs[name].T\n",
    "            results[name] = sims.numpy()\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def ensemble_scores(batch_scores, method=\"average\"):\n",
    "        arr = np.stack(list(batch_scores.values()), axis=0)\n",
    "        return arr.mean(axis=0) if method=='average' else arr.max(axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(y_true, y_scores, threshold=0.5):\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        m = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'macro_f1': f1_score(y_true, y_pred, average='macro'),\n",
    "            'micro_f1': f1_score(y_true, y_pred, average='micro')\n",
    "        }\n",
    "        try:\n",
    "            m['macro_auc'] = roc_auc_score(y_true, y_scores, average='macro')\n",
    "            m['micro_auc'] = roc_auc_score(y_true, y_scores, average='micro')\n",
    "        except ValueError:\n",
    "            m['macro_auc'] = m['micro_auc'] = -1\n",
    "        for i in range(y_true.shape[1]):\n",
    "            try:\n",
    "                m[f'auc_class_{i}'] = roc_auc_score(y_true[:,i], y_scores[:,i])\n",
    "            except ValueError:\n",
    "                m[f'auc_class_{i}'] = -1\n",
    "        return m\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_list = [\n",
    "        \"dmis-lab/biobert-v1.1\",\n",
    "        \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\",\n",
    "        \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    ]\n",
    "    name_map = {\n",
    "        \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\": \"biomedbert\",\n",
    "        \"dmis-lab/biobert-v1.1\":                                      \"biobert\",\n",
    "        \"emilyalsentzer/Bio_ClinicalBERT\":                           \"clinicalbert\"\n",
    "    }\n",
    "    candidate_labels = label_cols.copy()\n",
    "\n",
    "    texts  = raw_datasets['test']['text']\n",
    "    y_true = np.vstack(raw_datasets['test']['labels'])\n",
    "\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    zs = CLSEmbeddingZeroShot(model_list, candidate_labels, device=device)\n",
    "\n",
    "    batch_scores = zs.classify_batch(texts)\n",
    "    #ensemble_scores = zs.ensemble_scores(batch_scores, method='average')\n",
    "\n",
    "    for name, scores in batch_scores.items():\n",
    "      m = zs.evaluate(y_true, scores)\n",
    "      print(f\"\\n模型: {name}\\n\", m)\n",
    "\n",
    "    y_score_dict = {name: scores for name, scores in batch_scores.items()}\n",
    "    #y_score_dict[\"Ensemble\"] = ensemble_scores\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    for full_name, short_name in name_map.items():\n",
    "        scores = batch_scores[full_name]\n",
    "        n_labels = y_true.shape[1]\n",
    "\n",
    "        all_fpr = np.unique(\n",
    "            np.concatenate([\n",
    "                roc_curve(y_true[:, i], scores[:, i])[0]\n",
    "                for i in range(n_labels)\n",
    "            ])\n",
    "        )\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_labels):\n",
    "            fpr, tpr, _ = roc_curve(y_true[:, i], scores[:, i])\n",
    "            mean_tpr += np.interp(all_fpr, fpr, tpr)\n",
    "        mean_tpr /= n_labels\n",
    "\n",
    "        model_auc = auc(all_fpr, mean_tpr)\n",
    "        plt.plot(all_fpr, mean_tpr, lw=2, label=f\"{short_name} (AUC {model_auc:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", lw=1)\n",
    "    plt.title(\"Macro-average ROC Curves Across Zero-shot Models\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "scores = y_score_dict[\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\"]  # shape (n_samples, n_labels)\n",
    "class_names = [\n",
    "    \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\",\n",
    "    \"Lung Lesion\", \"Edema\", \"Consolidation\", \"Pneumonia\",\n",
    "    \"Atelectasis\", \"Pneumothorax\", \"Pleural Effusion\",\n",
    "    \"Pleural Other\", \"Fracture\", \"Support Devices\"\n",
    "]\n",
    "n_labels = scores.shape[1]\n",
    "roc_aucs = []\n",
    "pr_aucs  = []\n",
    "\n",
    "for i in range(n_labels):\n",
    "    roc_aucs.append(roc_auc_score(y_true[:, i], scores[:, i]))\n",
    "    pr_aucs.append(average_precision_score(y_true[:, i], scores[:, i]))\n",
    "\n",
    "x = np.arange(n_labels)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, roc_aucs, width, label=\"ROC AUC\", color=\"skyblue\")\n",
    "bars2 = ax.bar(x + width/2, pr_aucs,  width, label=\"PR AUC\",  color=\"gold\")\n",
    "\n",
    "for bar in bars1 + bars2:\n",
    "    h = bar.get_height()\n",
    "    ax.annotate(f\"{h:.3f}\",\n",
    "                xy=(bar.get_x() + bar.get_width()/2, h),\n",
    "                xytext=(0, 3), textcoords=\"offset points\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"AUC\")\n",
    "ax.set_title(\"Per-class ROC AUC and PR AUC Comparison (biomedbert)\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
